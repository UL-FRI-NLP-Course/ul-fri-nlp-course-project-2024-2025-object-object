%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FRI Data Science_report LaTeX Template
% Version 1.0 (28/1/2020)
%
% Jure Demšar (jure.demsar@fri.uni-lj.si)
%
% Based on MicromouseSymp article template by:
% Mathias Legrand (legrand.mathias@gmail.com)
% With extensive modifications by:
% Antonio Valente (antonio.luis.valente@gmail.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[fleqn,moreauthors,10pt]{ds_report}
\usepackage[english]{babel}

\graphicspath{{fig/}}
\usepackage{amsmath} % Needed for align environment
\usepackage{enumitem} % For compact lists
\usepackage{listings} % For code examples
\usepackage{booktabs} % For better tables
\usepackage{hyperref} % For hyperlinks


%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

% Header
\JournalInfo{FRI Natural language processing course 2025}

% Interim or final report
\Archive{Project report}
%\Archive{Final report}

% Article title
\PaperTitle{Integrating Structured Knowledge into Large Language Models}

% Authors (student competitors) and their info
\Authors{Konstantin Bojchevski, Matic Conradi, and Matjaž Kumin}

% Advisors
\affiliation{\textit{Advisor: Slavko Žitnik}}

% Keywords
\Keywords{LLMs, Knowledge Graphs, Slovenian Linguistics, Integration, Reasoning}
\newcommand{\keywordname}{Keywords}


%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{
This project explores integrating structured knowledge into Large Language Models (LLMs) to improve reasoning. We focus on incorporating knowledge graphs (KGs), particularly Slovenian linguistic data, to enhance question answering. We explore direct input augmentation, graph embedding-based integration, and attention-based fusion techniques. This report presents initial ideas and methods for integration, evaluating their impact on model performance. The project leverages the Slovenian Digital Dictionary Database to provide structured linguistic information to the LLM.
}

%----------------------------------------------------------------------------------------

\begin{document}

% Makes all text pages the same height
\flushbottom

% Print the title and abstract box
\maketitle

% Removes page numbering from the first page
\thispagestyle{empty}

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section*{Introduction}
Large Language Models (LLMs) have significantly advanced natural language understanding and generation. However, these models often struggle with complex reasoning tasks that require structured knowledge. This project explores techniques for integrating knowledge graphs (KGs) into LLMs to enhance their ability to accurately answer complex questions.

Our focus is on incorporating structured Slovenian linguistic data into LLMs via KGs. By leveraging semantic relationships within the Slovenian Digital Dictionary Database and other linguistic sources, we aim to improve model performance in accuracy and reasoning. This project will evaluate different integration techniques and their impact.

\section*{Related Work}
Several studies have explored combining knowledge graphs and LLMs to improve reasoning and language understanding. Key works include:

\begin{itemize}[noitemsep]
    \item \textbf{GraphGPT: Graph Instruction Tuning for Large Language Models} \cite{Tang2024GraphGPT}: Tang et al. (2024) explored tuning LLMs with graph-structured data, demonstrating the benefits of structured knowledge in language generation.
    \item \textbf{Combining Knowledge Graphs and Large Language Models} \cite{Kau2024CombiningKGLLM}: Kau et al. (2024) investigated hybrid approaches for combining KGs and LLMs.
    \item \textbf{Deep Bidirectional Language-Knowledge Graph Pretraining} \cite{Yasunaga2022DBLP}: Yasunaga et al. (2022) introduced pretraining methods integrating bidirectional knowledge graphs into LLMs.
    \item \textbf{Graph Language Models} \cite{Plenz2024GLM}: Plenz and Frank (2024) overview the use of graph-structured information with LLMs.
    \item \textbf{Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs} \cite{Zhang2024CoK}: Zhang et al. (2024) explored integrating knowledge reasoning into LLMs by learning from knowledge graphs.
    \item \textbf{InfuserKI: Enhancing Large Language Models with Knowledge Graphs via Infuser-Guided Knowledge Integration} \cite{Wang2024InfuserKI}: Wang et al. (2024) proposed enhancing LLMs with KGs via infuser-guided knowledge integration.
\end{itemize}

\section*{Initial Ideas}

The primary dataset for this project will be sourced from the Slovenian Digital Dictionary Database. This dataset contains structured linguistic information crucial for our integration techniques. We hypothesize that explicitly providing semantic relationships, word definitions, and contextual usages will enable the LLM to better understand and reason about complex linguistic queries. Additionally, we may incorporate other Slovenian linguistic resources and adapt existing datasets where necessary. The dataset will be preprocessed and merged with other sources, ensuring its compatibility with knowledge graph structures. Initial ideas include:

\begin{itemize}[noitemsep]
    \item \textbf{Semantic Enrichment:} Using the dictionary's hierarchical structure (e.g., word classes, part-of-speech tags) to provide richer semantic information to the LLM. This allows the model to better understand the relationships between words.
    \item \textbf{Contextualization:} Embedding definitions and example usages within the knowledge graph to provide the LLM with broader context for interpreting and reasoning about queries.  This includes example sentences from the dictionary.
    \item \textbf{Knowledge Graph Traversal:} Constructing complex queries that require the LLM to traverse the knowledge graph to retrieve specific relationships or definitions to arrive at an accurate answer. This tests the model's ability to utilize the KG for reasoning.
    \item \textbf{Cross-Lingual Transfer:} Investigating whether the structured knowledge from the Slovenian dictionary can be used to improve the performance of LLMs on related tasks in other Slavic languages.
\end{itemize}

\section*{Methods}

We will employ the following methods to integrate KGs into LLMs, focusing on the Slovenian linguistic context:

\begin{enumerate}[noitemsep]
    \item \textbf{Dataset Creation}:  We will construct a dataset of complex questions pertaining to Slovenian linguistics. These questions will be designed to require reasoning about the relationships defined in the Slovenian Digital Dictionary Database. Each question will be paired with a relevant KG subset extracted from the dictionary.
    \item \textbf{Direct Input Augmentation}: We will incorporate KG data directly into the input prompts. This will involve crafting prompts that include relevant facts, definitions, and relationships extracted from the knowledge graph, providing explicit hints to the LLM.  Different prompt engineering strategies will be explored.
    \item \textbf{Graph Embedding-Based Integration}:  We will convert KGs into vector embeddings using techniques like node2vec or graph convolutional networks (GCNs). These embeddings will then be fed into the LLM, potentially by concatenating them with the word embeddings or integrating them into the attention mechanism. We will experiment with different embedding dimensions and architectures.
    \item \textbf{Attention-Based Fusion Techniques}: We will modify the LLM's attention mechanism to incorporate KG-derived features. This could involve using the KG embeddings to bias the attention weights, allowing the model to focus on the most relevant nodes in the knowledge graph when processing the input query.
    \item \textbf{Evaluation}:  We will assess the effectiveness of each technique using metrics such as accuracy, precision, recall, and F1-score.  We will also analyze the types of errors made by the LLM with and without KG integration to understand the strengths and weaknesses of each approach.  Statistical significance testing will be used to validate the results.
\end{enumerate}


\bibliographystyle{unsrt}
\bibliography{report}

\end{document}
